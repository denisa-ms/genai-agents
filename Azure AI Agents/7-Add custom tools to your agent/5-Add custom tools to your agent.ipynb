{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CodeInterpreterTool' from 'azure.ai.projects.models' (c:\\Users\\dschlesinger\\code\\ongoing\\genai-agents\\.venv\\lib\\site-packages\\azure\\ai\\projects\\models\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprojects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AIProjectClient\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprojects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CodeInterpreterTool, FunctionTool, ToolSet\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01midentity\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DefaultAzureCredential\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Set, Dict, List, Optional\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'CodeInterpreterTool' from 'azure.ai.projects.models' (c:\\Users\\dschlesinger\\code\\ongoing\\genai-agents\\.venv\\lib\\site-packages\\azure\\ai\\projects\\models\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# ------------------------------------\n",
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT License.\n",
    "# ------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "    This sample demonstrates how to use agent operations with the \n",
    "    Azure AI Search tool from the Azure Agents service using a synchronous client.\n",
    "    To learn how to set up an Azure AI Search resource,\n",
    "    visit https://learn.microsoft.com/azure/search/search-get-started-portal\n",
    "\n",
    "USAGE:\n",
    "    Before running the sample:\n",
    "    Set these environment variables with your own values:\n",
    "    1) AZURE_AISTUDIO_PROJECT_CONN_STRING - The project connection string, as found in the overview page of your\n",
    "       Azure AI Foundry project.\n",
    "    2) AZURE_OPENAI_GPT4o_DEPLOYMENT_NAME - The deployment name of the AI model, as found under the \"Name\" column in \n",
    "       the \"Models + endpoints\" tab in your Azure AI Foundry project.\n",
    "    3) AZURE_AI_SEARCH_CONNECTION_ID - The connection ID of the Azure AI Search resource, as found in the \"Connections\" tab\n",
    "\"\"\"\n",
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import CodeInterpreterTool, FunctionTool, ToolSet\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from typing import Any, Callable, Set, Dict, List, Optional\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "load_dotenv()\n",
    "AZURE_OPENAI_GPT4o_DEPLOYMENT_NAME = \"gpt-4o\"\n",
    "AZURE_AISTUDIO_PROJECT_CONN_STRING = os.getenv(\"NL_TO_KQL_AZURE_AISTUDIO_PROJECT_CONN_STRING\")\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=AZURE_AISTUDIO_PROJECT_CONN_STRING,\n",
    ")\n",
    "\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    token = credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to be called by the agent as a custom tool\n",
    "import json\n",
    "\n",
    "def recent_snowfall(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches recent snowfall totals for a given location.\n",
    "    :param location: The city name.\n",
    "    :return: Snowfall details as a JSON string.\n",
    "    \"\"\"\n",
    "    mock_snow_data = {\"Seattle\": \"0 inches\", \"Denver\": \"2 inches\"}\n",
    "    snow = mock_snow_data.get(location, \"Data not available.\")\n",
    "    return json.dumps({\"location\": location, \"snowfall\": snow})\n",
    "\n",
    "user_functions: Set[Callable[..., Any]] = {\n",
    "    recent_snowfall,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent toolset with user functions\n",
    "functions = FunctionTool(user_functions)\n",
    "toolset = ToolSet()\n",
    "toolset.add(functions)\n",
    "\n",
    "# Create your agent with the toolset\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=AZURE_OPENAI_GPT4o_DEPLOYMENT_NAME,\n",
    "    name=\"snowfall-agent\",\n",
    "    instructions=\"You are a weather assistant tracking snowfall. Use the provided functions to answer questions.\",\n",
    "    toolset=toolset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create thread for communication\n",
    "def call_agent(question):\n",
    "    thread = project_client.agents.create_thread()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "    # Create message to thread\n",
    "    message = project_client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=question\n",
    "    )\n",
    "    print(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "    # Create and process agent run in thread with tools\n",
    "    run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "    print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "        # Fetch and log all messages\n",
    "        \n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    print(f\"Messages: {messages}\")\n",
    "\n",
    "    # print(messages[\"data\"][0][\"content\"][0][\"text\"][\"value\"])\n",
    "    # Fetch and log all messages in chronological order\n",
    "    messages_data = messages[\"data\"]\n",
    "\n",
    "    # Sort messages by creation time (ascending)\n",
    "    sorted_messages = sorted(messages_data, key=lambda x: x[\"created_at\"])\n",
    "\n",
    "    print(\"\\n--- Thread Messages (sorted) ---\")\n",
    "    for msg in sorted_messages:\n",
    "        role = msg[\"role\"].upper()\n",
    "        # Each 'content' is a list; get the first text block if present\n",
    "        content_blocks = msg.get(\"content\", [])\n",
    "        text_value = \"\"\n",
    "        if content_blocks and content_blocks[0][\"type\"] == \"text\":\n",
    "            text_value = content_blocks[0][\"text\"][\"value\"]\n",
    "        print(f\"{role}: {text_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread, ID: thread_mG5qqMPufjWVNvSWmhn7ZOIy\n",
      "Created message, ID: msg_SmCyQ37LiZnBKuMFeciaKt91\n",
      "Run finished with status: completed\n",
      "Messages: {'object': 'list', 'data': [{'id': 'msg_hg4vtpNg5oKXT8LAGgBzGu2d', 'object': 'thread.message', 'created_at': 1743241266, 'assistant_id': 'asst_LMKRzIYi3ICl96x38StdlAZE', 'thread_id': 'thread_mG5qqMPufjWVNvSWmhn7ZOIy', 'run_id': 'run_nqlSkxThpePVOUgvYXzqQjpW', 'role': 'assistant', 'content': [{'type': 'text', 'text': {'value': 'The recent snowfall in Seattle is 0 inches.', 'annotations': []}}], 'attachments': [], 'metadata': {}}, {'id': 'msg_SmCyQ37LiZnBKuMFeciaKt91', 'object': 'thread.message', 'created_at': 1743241261, 'assistant_id': None, 'thread_id': 'thread_mG5qqMPufjWVNvSWmhn7ZOIy', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': 'What is the recent snowfall in Seattle?', 'annotations': []}}], 'attachments': [], 'metadata': {}}], 'first_id': 'msg_hg4vtpNg5oKXT8LAGgBzGu2d', 'last_id': 'msg_SmCyQ37LiZnBKuMFeciaKt91', 'has_more': False}\n",
      "\n",
      "--- Thread Messages (sorted) ---\n",
      "USER: What is the recent snowfall in Seattle?\n",
      "ASSISTANT: The recent snowfall in Seattle is 0 inches.\n"
     ]
    }
   ],
   "source": [
    "# Send a prompt to the agent\n",
    "user_prompt = \"What is the recent snowfall in Seattle?\"\n",
    "\n",
    "call_agent(user_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
